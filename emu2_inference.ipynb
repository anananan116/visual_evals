{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12edb71c-f69a-436c-9497-dd678a5887e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import requests\n",
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import init_empty_weights, infer_auto_device_map, load_checkpoint_and_dispatch\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.datasets import CocoCaptions\n",
    "import torchvision.transforms as T\n",
    "from typing import Any, Callable, List, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568ee9b-5e7f-4abb-87ad-6363fa2f111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoCaptions_custimized(CocoCaptions):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Union[str, Path],\n",
    "        annFile: str,\n",
    "        slice: int = 5000,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        transforms: Optional[Callable] = None,\n",
    "        ) -> None:\n",
    "        super().__init__(root, transforms, transform, target_transform)\n",
    "        from pycocotools.coco import COCO\n",
    "\n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.ids = self.ids[:slice]\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any, Any]:\n",
    "\n",
    "        if not isinstance(index, int):\n",
    "            raise ValueError(f\"Index must be of type integer, got {type(index)} instead.\")\n",
    "\n",
    "        id = self.ids[index]\n",
    "        image = self._load_image(id)\n",
    "        target = self._load_target(id)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "\n",
    "        return id, image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace9157-e4e3-4433-a4b1-498dc9ffcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_DATASET_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
    "OPENAI_DATASET_STD = (0.26862954, 0.26130258, 0.27577711)\n",
    "transform = T.Compose(\n",
    "            [\n",
    "                T.Resize(\n",
    "                    (448, 448), interpolation=T.InterpolationMode.BICUBIC\n",
    "                ),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(OPENAI_DATASET_MEAN, OPENAI_DATASET_STD),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2557ad0-58b6-4153-8c48-3b46cd15b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = CocoCaptions_custimized(root = './val2014', annFile = './annotations/captions_val2014.json', transform=transform)\n",
    "batch_size = 1\n",
    "dataloader = DataLoader(cap, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbeaf5a-58fb-41ce-b145-8be1599ca986",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/Emu2\")\n",
    "\n",
    "with init_empty_weights():\n",
    "     model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"BAAI/Emu2\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f288434c-505b-4da1-8a9c-82b00f43e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_map = infer_auto_device_map(model, max_memory={0:'36GiB',1:'38GiB',}, no_split_module_classes=['Block','LlamaDecoderLayer'])  \n",
    "device_map[\"model.decoder.lm.lm_head\"] = 0\n",
    "\n",
    "model = load_checkpoint_and_dispatch(\n",
    "    model, \n",
    "    '/root/.cache/huggingface/hub/models--BAAI--Emu2/snapshots/fa835ec101e52da5e081695107e1ddd3c7c4d88a',\n",
    "    device_map=device_map).eval()\n",
    "query = '[<IMG_PLH>]Describe the image in details:' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e67943-1ed3-44e4-8fd2-659dad7d9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for ids, image, target in tqdm(dataloader):\n",
    "    inputs = model.build_input_ids(\n",
    "        text=[query] * batch_size,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    image = image.to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "         outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            image=image.to(torch.bfloat16),\n",
    "            max_new_tokens=64,\n",
    "            length_penalty=-1)\n",
    "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    for i in range(len(ids)):\n",
    "        results[int(ids[i])] = (output_text[i], target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49f9e9-4f0d-4d67-b5e1-a37a7728c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results in the format of {image_id: [generated_caption, [target_caption1, target_caption2, ...]], ...}\n",
    "with open('captions.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95b88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
